{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f26f6d5",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with \n",
    "an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450f1f1",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical functions used to describe the probabilities of different outcomes in a discrete random variable (PMF) or a continuous random variable (PDF).\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "The PMF is used for discrete random variables, which are variables that can only take on distinct values. The PMF gives the probability of each possible outcome.\n",
    "Let's consider an example of rolling a fair six-sided die. The possible outcomes are the numbers 1 to 6. The PMF for this scenario would be:\n",
    "\n",
    "PMF(x) = 1/6, for x = 1, 2, 3, 4, 5, 6\n",
    "\n",
    "In this case, the PMF assigns equal probabilities of 1/6 to each possible outcome since the die is fair.\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "The PDF is used for continuous random variables, which can take on any value within a certain range. The PDF gives the probability density at each possible value.\n",
    "For example, let's consider the height of adult males. The height can vary continuously within a range. Suppose the PDF of the height of adult males follows a normal distribution with a mean of 175 cm and a standard deviation of 5 cm. The PDF for this scenario would be:\n",
    "\n",
    "PDF(x) = (1 / (σ * √(2π))) * e^(-((x - μ)^2) / (2σ^2))\n",
    "\n",
    "Where μ is the mean (175 cm) and σ is the standard deviation (5 cm).\n",
    "\n",
    "In this case, the PDF provides the probability density at any given height value. Higher density values indicate that a height is more likely to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028585f",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ad1ba",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a concept in probability theory and statistics that describes the probability distribution of a random variable. It provides information about the likelihood of a random variable taking on a certain value or falling within a specific range.\n",
    "\n",
    "The CDF of a random variable X, denoted as F(x), is defined as the probability that X takes on a value less than or equal to x. Mathematically, it can be expressed as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "The CDF provides a cumulative view of the probability distribution by accumulating the probabilities of all values less than or equal to a given value. It ranges from 0 to 1, where F(x) = 0 indicates that the random variable X is less than any possible value, and F(x) = 1 indicates that the random variable X is greater than or equal to any possible value.\n",
    "\n",
    "To understand the concept better, let's consider an example. Suppose we have a random variable X representing the heights of a group of people. The CDF of X would tell us the probability that a randomly selected person from the group has a height less than or equal to a specific value.\n",
    "\n",
    "For instance, let's say we calculate the CDF for X at the value x = 170 cm and find that F(170) = 0.75. This means that there is a 75% probability that a randomly chosen person from the group has a height less than or equal to 170 cm.\n",
    "\n",
    "The CDF is used for several reasons:\n",
    "\n",
    "Probability calculations: The CDF allows us to calculate probabilities associated with random variables. By evaluating the CDF at different values, we can determine the likelihood of specific events occurring.\n",
    "\n",
    "Quantile estimation: The CDF can be used to estimate percentiles or quantiles of a distribution. For example, by finding the value of x for which F(x) = 0.5, we can identify the median of the distribution.\n",
    "\n",
    "Distribution comparison: CDFs can be compared to analyze and compare different probability distributions. By plotting multiple CDFs on the same graph, we can visually assess similarities, differences, and other characteristics of the distributions.\n",
    "\n",
    "Random variable transformation: The CDF can be used to transform a random variable from one distribution to another using a technique called inverse transform sampling. This is particularly useful in generating random numbers following a desired probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71028b",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model? \n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f823adf",
   "metadata": {},
   "source": [
    "\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, is widely used as a model in various fields due to its mathematical properties and its ability to approximate many real-world phenomena. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Height of individuals: The distribution of heights in a population often follows a roughly normal distribution. The mean and standard deviation of the normal distribution can describe the average height and the variation around the mean, respectively.\n",
    "\n",
    "Test scores: In educational assessments, test scores often exhibit a normal distribution. The mean represents the average score, while the standard deviation provides information about the spread of scores around the mean.\n",
    "\n",
    "Measurement errors: When measuring physical quantities, random errors can often be modeled using a normal distribution. The mean of the distribution represents the true value being measured, and the standard deviation captures the uncertainty or variation in the measurements.\n",
    "\n",
    "Stock market returns: Daily returns of stock prices are often assumed to follow a normal distribution. The mean of the distribution can represent the average return, while the standard deviation reflects the volatility or risk associated with the stock.\n",
    "\n",
    "IQ scores: Intelligence quotient (IQ) scores in a population tend to be normally distributed. The mean IQ represents the average intelligence level, and the standard deviation indicates the spread of IQ scores around the mean.\n",
    "\n",
    "Now, let's discuss how the parameters of the normal distribution relate to the shape of the distribution:\n",
    "\n",
    "Mean (μ): The mean determines the location or center of the normal distribution. It represents the average value around which the data is expected to cluster. Shifting the mean to the right or left will shift the entire distribution accordingly.\n",
    "\n",
    "Standard Deviation (σ): The standard deviation controls the spread or dispersion of the data. A smaller standard deviation indicates that the data points are closer to the mean, resulting in a narrower and taller bell curve. Conversely, a larger standard deviation leads to a broader and flatter distribution.\n",
    "\n",
    "Variance (σ^2): The variance is the square of the standard deviation. It quantifies the average squared distance of data points from the mean. Like the standard deviation, a smaller variance results in a narrower distribution, while a larger variance leads to a wider distribution.\n",
    "\n",
    "In summary, the mean determines the center of the normal distribution, while the standard deviation (or variance) influences the spread or dispersion of the data. By adjusting these parameters, the shape of the normal distribution can be altered to fit different datasets or model various phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ae070",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal \n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f8c89",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is of great importance in statistics and data analysis due to its wide range of applications and mathematical properties. Here are a few reasons why the normal distribution is significant:\n",
    "\n",
    "Central Limit Theorem: The normal distribution plays a central role in the Central Limit Theorem (CLT). According to the CLT, when independent random variables are added, their sum tends to follow a normal distribution, regardless of the shape of the original variables. This property allows researchers to make inferences about populations based on sample means.\n",
    "\n",
    "Data Modeling: Many real-life phenomena follow a normal distribution, making it a suitable choice for modeling various variables. Some examples include:\n",
    "\n",
    "Heights and weights of individuals in a population.\n",
    "IQ scores in a large sample of people.\n",
    "Errors in measurements, such as instrument readings or experimental observations, assuming the errors are normally distributed.\n",
    "Test scores, when the test is well-designed and the population is large enough.\n",
    "Statistical Inference: The normal distribution allows for the application of various statistical tests and techniques. Hypothesis testing, confidence intervals, and regression analysis often assume normality for the underlying data. These techniques are widely used in fields such as economics, social sciences, and quality control.\n",
    "\n",
    "Standardization: The normal distribution has convenient properties for standardizing data. By transforming a dataset into z-scores (subtracting the mean and dividing by the standard deviation), the data is converted into a standard normal distribution with a mean of 0 and a standard deviation of 1. This standardization enables comparisons and calculations of probabilities.\n",
    "\n",
    "Prediction and Decision Making: In many cases, assuming a normal distribution for a variable allows for reliable predictions and decision making. The use of normal distribution-based models, such as linear regression or time series forecasting, helps estimate future values and make informed decisions based on probabilities and confidence intervals.\n",
    "\n",
    "Real-life examples of variables that often follow a normal distribution include:\n",
    "\n",
    "Heights of individuals in a large population.\n",
    "\n",
    "Weights of manufactured products that are within specified tolerance limits.\n",
    "\n",
    "Exam scores of a large group of students following a well-designed test.\n",
    "\n",
    "Errors in measurements, assuming they are small and independent.\n",
    "\n",
    "Blood pressure readings in a healthy population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef2919",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli \n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9915d",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (usually denoted as 1) or failure (usually denoted as 0). It is named after Jacob Bernoulli, a Swiss mathematician.\n",
    "\n",
    "In the Bernoulli distribution, there is a single trial or observation with a fixed probability of success, often denoted as \"p.\" The probability of failure is equal to 1 minus the probability of success, which can be denoted as \"q\" or (1 - p).\n",
    "\n",
    "An example of the Bernoulli distribution is flipping a fair coin. If we define success as obtaining a \"heads\" outcome, and failure as obtaining a \"tails\" outcome, then the Bernoulli distribution can be used to model this situation. The probability of success (getting a \"heads\") is 0.5, and the probability of failure (getting a \"tails\") is also 0.5.\n",
    "\n",
    "The difference between the Bernoulli distribution and the binomial distribution lies in the number of trials or observations. The Bernoulli distribution is concerned with a single trial, while the binomial distribution deals with a fixed number of independent and identical Bernoulli trials.\n",
    "\n",
    "The binomial distribution models the number of successes that occur in a fixed number of Bernoulli trials. It is characterized by two parameters: the number of trials, denoted as \"n,\" and the probability of success in each trial, denoted as \"p.\"\n",
    "\n",
    "For example, let's consider flipping a fair coin 10 times. Each coin flip can be modeled as a Bernoulli trial with a probability of success (getting a \"heads\") equal to 0.5. If we want to know the probability of getting exactly 3 heads in these 10 trials, we would use the binomial distribution with parameters n = 10 (number of trials) and p = 0.5 (probability of success). The binomial distribution allows us to calculate the probability mass function (PMF) for different numbers of successes in a given number of trials.\n",
    "\n",
    "In summary, the Bernoulli distribution is used to model a single trial with two possible outcomes, while the binomial distribution models the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca38478",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset \n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater \n",
    "than 60? Use the appropriate formula and show your calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c8961",
   "metadata": {},
   "source": [
    "let's first calculate Z-score = (60-mean)/standard deviation = 1\n",
    "\n",
    "Now we have to look into Z Table for the checking the observation which are left side of 60 - 0.8413 means 84.13%. \n",
    "\n",
    "So, the probability that a randomly selected observation will be greater than 60 will be (1-0.8413) = 0.1587"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d176b9",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558ce5b",
   "metadata": {},
   "source": [
    "A uniform distribution, also known as a rectangular distribution, is a probability distribution in which all outcomes or values within a given range are equally likely to occur. In other words, it is a continuous probability distribution where every value within a specified interval has an equal probability of being observed.\n",
    "\n",
    "To better understand the concept, let's consider an example. Imagine you have a fair six-sided die. The faces of the die are numbered from 1 to 6. When you roll the die, the outcome or value you get is random, but each outcome has an equal probability of occurring.\n",
    "\n",
    "In this case, the uniform distribution is represented by the probabilities of rolling each number on the die. Since the die is fair, each of the six numbers has a 1/6 chance of being rolled. This means that the probability of rolling any specific number, such as 1, 2, 3, 4, 5, or 6, is 1/6.\n",
    "\n",
    "The probability density function (PDF) of a uniform distribution can be represented by a horizontal line within a specified interval. In our example, the PDF would be a flat line at 1/6 for the interval [1, 6], indicating that all numbers in this range have an equal likelihood of being rolled.\n",
    "\n",
    "It's important to note that the uniform distribution is not limited to dice rolls but can also be applied to various situations, such as generating random numbers within a given range, selecting random points within a defined area, or modeling situations where all outcomes have the same probability of occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad6cd7",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2be1a8",
   "metadata": {},
   "source": [
    "A z-score is a statistical measurement that tells you how far away from the mean (or average) your datum lies in a normally distributed sample.\n",
    "\n",
    "The standard score (more commonly referred to as a z-score) is a very useful statistic because it (a) allows us to calculate the probability of a score occurring within our normal distribution and (b) enables us to compare two scores that are from different normal distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be7e67",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20707bc",
   "metadata": {},
   "source": [
    "What is the central limit theorem?\n",
    "Central Limit Theorem | Formula, Definition & Examples\n",
    "The central limit theorem says that the sampling distribution of the mean will always be normally distributed, as long as the sample size is large enough. Regardless of whether the population has a normal, Poisson, binomial, or any other distribution, the sampling distribution of the mean will be normal.\n",
    "\n",
    "The central limit theorem is important in Statistics because it: enables reasonably accurate probabilities to be determined for events involving the sample average when the sample size is large regardless of the distribution of the variable.\n",
    "\n",
    "This allows for easier statistical analysis and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b70687",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9ce7a",
   "metadata": {},
   "source": [
    "the assumptions behind CLT:\n",
    "\n",
    "The data must adhere to the randomization rule. It needs to be sampled at random.\n",
    "The samples should be unrelated to one another. One sample should not impact the others.\n",
    "When taking samples without replacement, the sample size should not exceed 10% of the population.\n",
    "When the population is symmetric, a sample size of 30 is generally considered reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8af92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
