{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7485a86b",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef256a28",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means between two or more groups. It relies on certain assumptions for its validity. Here are the key assumptions required to use ANOVA:\n",
    "\n",
    "Independence: The observations within each group are assumed to be independent of each other. This means that the values or measurements in one group should not be influenced by or related to the values in another group.\n",
    "\n",
    "Normality: The data within each group should follow a normal distribution. This assumption implies that the distribution of values within each group should be symmetric and bell-shaped.\n",
    "\n",
    "Homogeneity of variance: The variances of the data in each group should be approximately equal. In other words, the spread or variability of the values should be similar across all groups.\n",
    "\n",
    "Homogeneity of regression slopes (for factorial ANOVA): This assumption applies specifically to factorial ANOVA, which involves the interaction between categorical and continuous variables. It assumes that the relationship between the continuous variable and the response variable is the same across all levels of the categorical variable.\n",
    "\n",
    "Violations of these assumptions can impact the validity of ANOVA results. Here are examples of violations for each assumption:\n",
    "\n",
    "Independence: Violations of independence can occur when there is dependence or correlation between observations in different groups. For example, in a study where family members are grouped together, their responses may be correlated, violating the independence assumption.\n",
    "\n",
    "Normality: If the data within groups significantly deviates from a normal distribution, it can impact the validity of ANOVA results. For instance, if the data is heavily skewed or has outliers, it may violate the normality assumption.\n",
    "\n",
    "Homogeneity of variance: Violations of this assumption can occur when the variances of the groups are significantly different. This can lead to unequal representation of variability in the groups, affecting the ANOVA results. For example, if one group has much higher variability than the others, it can violate the assumption.\n",
    "\n",
    "Homogeneity of regression slopes: This assumption can be violated when the relationship between the continuous variable and the response variable differs across levels of the categorical variable. For instance, if the effect of a treatment on an outcome varies depending on different demographic groups, it violates the assumption.\n",
    "\n",
    "When these assumptions are violated, it may be necessary to consider alternative statistical tests or data transformations to obtain reliable and valid results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbe240",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135ee32",
   "metadata": {},
   "source": [
    "The three main types of ANOVA are:\n",
    "\n",
    "One-Way ANOVA: This type of ANOVA is used when you have one categorical independent variable (also known as a factor) with three or more levels, and a continuous dependent variable. The purpose of One-Way ANOVA is to determine if there are any significant differences in the means of the dependent variable across the different levels of the independent variable. It is often used when comparing the means of multiple groups or conditions. For example, a One-Way ANOVA can be used to compare the average test scores of students from different schools.\n",
    "\n",
    "Two-Way ANOVA: Two-Way ANOVA is used when you have two categorical independent variables, also known as factors, and a continuous dependent variable. It allows you to examine the main effects of each independent variable as well as the interaction between them. The main effects represent the effects of each independent variable separately, while the interaction effect captures the combined effect of both variables. Two-Way ANOVA is commonly used in experimental designs where you want to investigate the effects of two factors simultaneously. For example, you could use Two-Way ANOVA to analyze the impact of both gender and age group on response time in a cognitive task.\n",
    "\n",
    "Factorial ANOVA: Factorial ANOVA is an extension of Two-Way ANOVA and is used when you have two or more categorical independent variables (factors) and a continuous dependent variable. It allows for the examination of main effects and interaction effects among the factors. The number of levels within each factor determines the number of cells in the factorial design. Factorial ANOVA is useful when you want to explore the combined effects of multiple factors on the dependent variable. For example, in a study on the effectiveness of a drug, you could use Factorial ANOVA to investigate the effects of dosage (low vs. high) and treatment duration (short vs. long) on patient recovery time.\n",
    "\n",
    "These types of ANOVA provide statistical tests to determine whether the observed differences in means between groups or conditions are statistically significant, helping to identify the factors or interactions that have a significant impact on the dependent variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345cbe46",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd50a0a",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the decomposition of the total variance observed in the data into different components that are associated with various sources of variation. Understanding this concept is important because it allows us to quantify the contributions of different factors and sources of variability to the overall variation in the data. This partitioning provides valuable insights into the significance and magnitude of these factors, helping us draw meaningful conclusions from the ANOVA analysis.\n",
    "\n",
    "In ANOVA, the total variance observed in the data is divided into two main components:\n",
    "\n",
    "Between-group variance (explained variance): This component represents the variation in the data that can be attributed to the differences between the groups or conditions being compared. It captures the effects of the independent variable(s) on the dependent variable. The between-group variance is also known as the \"explained variance\" because it explains the variation accounted for by the factors being studied.\n",
    "\n",
    "Within-group variance (unexplained variance or error variance): This component represents the variation in the data that cannot be explained by the differences between the groups or conditions. It reflects the random variability or \"noise\" within each group, which is not attributable to the factors being examined. The within-group variance is also referred to as the \"unexplained variance\" or \"error variance\" because it represents the residual variation that is not accounted for by the model.\n",
    "\n",
    "By understanding the partitioning of variance, we can calculate various statistics in ANOVA, such as the F-statistic, which compares the ratio of between-group variance to within-group variance. This ratio provides a measure of how much the variation between groups exceeds the random variation within groups, indicating whether there are statistically significant differences among the groups.\n",
    "\n",
    "Moreover, the partitioning of variance allows us to estimate the effect size, which quantifies the magnitude of the differences between groups. Effect size measures, such as eta-squared or partial eta-squared, indicate the proportion of total variance in the dependent variable that can be attributed to the independent variable(s). This information helps to assess the practical significance or importance of the effects observed in the ANOVA analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51acd4",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77607797",
   "metadata": {},
   "source": [
    "To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, we use statsmodels library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b552ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 1120.0\n",
      "Explained Sum of Squares (SSE): 1120.0\n",
      "Residual Sum of Squares (SSR): 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate example data\n",
    "group1 = [10, 12, 14, 16, 18]\n",
    "group2 = [20, 22, 24, 26, 28]\n",
    "group3 = [30, 32, 34, 36, 38]\n",
    "data = group1 + group2 + group3\n",
    "labels = ['Group 1'] * len(group1) + ['Group 2'] * len(group2) + ['Group 3'] * len(group3)\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Data': data, 'Group': labels})\n",
    "\n",
    "# Fit one-way ANOVA model\n",
    "model = ols('Data ~ Group', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract sums of squares\n",
    "SST = np.sum((df['Data'] - np.mean(df['Data'])) ** 2)\n",
    "SSE = np.sum(anova_table['sum_sq'])\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b0cb7e",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51463d2",
   "metadata": {},
   "source": [
    "Please refer solution of Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50e4b0",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2dcec",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences between the means of the groups being compared. The p-value associated with the F-statistic indicates the probability of obtaining such an F-statistic or a more extreme value if the null hypothesis (no significant differences between group means) is true.\n",
    "\n",
    "In this scenario, with an F-statistic of 5.23 and a p-value of 0.02, we can conclude the following:\n",
    "\n",
    "The F-statistic: The F-statistic of 5.23 indicates that there is some evidence of variation in the means of the groups being compared. The larger the F-statistic, the stronger the evidence for significant differences between the groups.\n",
    "\n",
    "The p-value: The p-value of 0.02 indicates that the probability of obtaining an F-statistic of 5.23 or more extreme (i.e., in favor of the alternative hypothesis) is 0.02. Typically, a significance level (alpha) of 0.05 is used as a threshold. Since the p-value (0.02) is less than the significance level (0.05), we have sufficient evidence to reject the null hypothesis. This means that there are significant differences between the group means.\n",
    "\n",
    "Interpretation: Based on the results, we can conclude that there are statistically significant differences between the groups. However, the one-way ANOVA does not provide specific information on which groups are different from each other. To determine which groups are significantly different, additional post-hoc tests, such as Tukey's HSD or pairwise comparisons, can be conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81997849",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb2bf7",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration to ensure valid and reliable results. Here are a few approaches to handling missing data in this context:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion): This method involves excluding any participant with missing data from the analysis. It is the simplest approach but can lead to reduced sample size and potentially biased results if the missingness is related to the variables being studied. Listwise deletion can introduce selection biases and decrease the representativeness of the sample.\n",
    "\n",
    "Pairwise Deletion: With this approach, you include all available data for each participant in the analysis. The missing data points are ignored for each specific comparison or test. While this method maximizes the use of available data, it can lead to different sample sizes for different comparisons, potentially affecting statistical power and precision of the estimates.\n",
    "\n",
    "Imputation: Imputation involves replacing missing values with estimated values based on the observed data. There are various imputation methods, including mean imputation, regression imputation, multiple imputation, etc. Imputation can help retain sample size and preserve statistical power. However, the choice of imputation method can impact the results. If the imputation is not performed appropriately, it may introduce bias or distort the true relationships in the data.\n",
    "\n",
    "Potential consequences of using different methods to handle missing data in a repeated measures ANOVA include:\n",
    "\n",
    "Biased Results: If missingness is related to the variables being studied or other factors, the chosen method for handling missing data can introduce bias. Complete case analysis may lead to biased estimates if the missing data are not missing completely at random (MCAR). Imputation methods may also introduce bias if the imputation model is misspecified.\n",
    "\n",
    "Reduced Statistical Power: Excluding participants or observations with missing data through complete case analysis or listwise deletion reduces the sample size. This reduction in sample size can lead to decreased statistical power and may limit the ability to detect significant effects.\n",
    "\n",
    "Precision and Generalizability: Different methods for handling missing data can lead to variations in estimated effects, standard errors, and confidence intervals. This affects the precision of the estimates and the generalizability of the findings to the population of interest.\n",
    "\n",
    "Assumptions Violation: Missing data can violate the assumptions of repeated measures ANOVA, such as the assumption of missingness being completely at random (MCAR). If the missingness is related to unobserved variables or the dependent variable itself, it can impact the validity of the analysis and the interpretation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf69f8",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421275c4",
   "metadata": {},
   "source": [
    "After conducting an ANOVA and finding a significant overall effect, post-hoc tests are used to determine which specific group differences are significant. Several common post-hoc tests are available, each with its own assumptions and applications. Here are a few examples:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD): Tukey's HSD is widely used for post-hoc testing in ANOVA. It controls the familywise error rate, allowing for simultaneous comparisons of all possible pairs of groups. Tukey's HSD is appropriate when you have a balanced design (equal sample sizes) and homogeneity of variances. It is a conservative test and tends to have wider confidence intervals. Example situation: In a study comparing the effectiveness of three different treatment groups, ANOVA indicates a significant difference. Tukey's HSD can be used to determine which specific pairs of treatment groups differ significantly from each other.\n",
    "\n",
    "Bonferroni Correction: The Bonferroni correction adjusts the significance level to control for multiple comparisons. It is a conservative approach that divides the desired alpha level by the number of comparisons being made. The Bonferroni correction is more stringent compared to other post-hoc tests and reduces the likelihood of Type I errors. Example situation: When conducting multiple pairwise comparisons between groups, and there is a concern about inflating the overall Type I error rate, the Bonferroni correction can be applied.\n",
    "\n",
    "Dunnett's Test: Dunnett's test is used when comparing multiple treatment groups to a control group. It controls the familywise error rate, allowing for comparisons against a single control group while taking into account the multiple comparisons. Dunnett's test assumes homogeneity of variances among the treatment groups. Example situation: In a drug study where multiple experimental groups are being compared to a control group, Dunnett's test can be employed to determine if any of the experimental groups differ significantly from the control group.\n",
    "\n",
    "Scheffe's Test: Scheffe's test is a more liberal post-hoc test that can be used when there are unequal sample sizes or unequal variances among groups. It provides a wider range of application but tends to have lower statistical power compared to Tukey's HSD or Bonferroni correction. Example situation: When dealing with unequal sample sizes or unequal variances among groups, Scheffe's test can be utilized to determine significant group differences.\n",
    "\n",
    "The choice of post-hoc test depends on the specific research question, assumptions of the data, and the design of the study. It is crucial to consider the underlying assumptions, such as equal variances and sample sizes, and select the appropriate post-hoc test accordingly. Consulting a statistician can help ensure the most suitable test is chosen for a particular analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9098b",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9567af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 0.5\n",
      "p-value: 0.6186248513251719\n",
      "Failed to reject the null hypothesis and conclude that there are no significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "diet_A = [2, 4, 6, 8, 10]\n",
    "diet_B = [1, 3, 5, 7, 9]\n",
    "diet_C = [0, 2, 4, 6, 8]\n",
    "\n",
    "all_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "group_labels = ['A'] * len(diet_A) + ['B'] * len(diet_B) + ['C'] * len(diet_C)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "sig_lvl = 0.05 #assume\n",
    "if p_value < sig_lvl:\n",
    "    print(\"Reject the null hypothesis and conclude that there are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"Failed to reject the null hypothesis and conclude that there are no significant differences between the mean weight loss of the three diets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa6ffe",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0426a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects:\n",
      "Program: F = 0.03064250516088527 p = 0.9698600966230347\n",
      "Experience: F = 0.6255650940587465 p = 0.4367335116637626\n",
      "Interaction effect:\n",
      "Program:Experience: F = 2.478325417150803 p = 0.10508844080853426\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate example data\n",
    "n = 30\n",
    "programs = np.random.choice(['A', 'B', 'C'], size=n)\n",
    "experience = np.random.choice(['Novice', 'Experienced'], size=n)\n",
    "time = np.random.normal(loc=10, scale=2, size=n)\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Program': programs, 'Experience': experience, 'Time': time})\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "model = ols('Time ~ Program + Experience + Program:Experience', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract F-statistics and p-values\n",
    "program_F = anova_table.loc['Program', 'F']\n",
    "program_pvalue = anova_table.loc['Program', 'PR(>F)']\n",
    "\n",
    "experience_F = anova_table.loc['Experience', 'F']\n",
    "experience_pvalue = anova_table.loc['Experience', 'PR(>F)']\n",
    "\n",
    "interaction_F = anova_table.loc['Program:Experience', 'F']\n",
    "interaction_pvalue = anova_table.loc['Program:Experience', 'PR(>F)']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main effects:\")\n",
    "print(\"Program: F =\", program_F, \"p =\", program_pvalue)\n",
    "print(\"Experience: F =\", experience_F, \"p =\", experience_pvalue)\n",
    "print(\"Interaction effect:\")\n",
    "print(\"Program:Experience: F =\", interaction_F, \"p =\", interaction_pvalue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bac2dd",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ebdda1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.3511267852812807\n",
      "p-value: 0.0009638719426795379\n",
      "Reject the null hypothesis and conclude that there are significant differences in test scores between the control group and the experimental group.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(0)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=12, size=100)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "sig_lvl = 0.05 #assume\n",
    "if p_value < sig_lvl:\n",
    "    print(\"Reject the null hypothesis and conclude that there are significant differences in test scores between the control group and the experimental group.\")\n",
    "else:\n",
    "    print(\"Failed to reject the null hypothesis and conclude that there are no significant differences in test scores between the control group and the experimental group.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffde672",
   "metadata": {},
   "source": [
    "If the results are significant, you can follow up with post-hoc tests to determine which specific groups differ significantly from each other. However, since this is a two-group comparison, a post-hoc test is not necessary in this case. Instead, the two-sample t-test already provides information about the significant difference between the control and experimental groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c7de4",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ee6e25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            df        sum_sq      mean_sq          F    PR(>F)\n",
      "Store      2.0   9143.459501  4571.729750  10.908681  0.000095\n",
      "C(Day)    29.0  10662.446301   367.670562   0.877305  0.642677\n",
      "Residual  58.0  24307.276707   419.090978        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(0)\n",
    "store_A_sales = np.random.normal(loc=100, scale=20, size=30)\n",
    "store_B_sales = np.random.normal(loc=90, scale=18, size=30)\n",
    "store_C_sales = np.random.normal(loc=95, scale=22, size=30)\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Day': range(1, 31),\n",
    "                   'Store A': store_A_sales,\n",
    "                   'Store B': store_B_sales,\n",
    "                   'Store C': store_C_sales})\n",
    "\n",
    "# Convert the data to long format\n",
    "df_long = pd.melt(df, id_vars='Day', var_name='Store', value_name='Sales')\n",
    "\n",
    "# Fit repeated measures ANOVA model\n",
    "model = ols('Sales ~ Store + C(Day)', data=df_long).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5c168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5763f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
