{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c782416",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79205c",
   "metadata": {},
   "source": [
    "Underfitting: A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data, i.e., it only performs well on training data but performs poorly on testing data.\n",
    "Underfitting destroys the accuracy of our machine learning model.\n",
    "\n",
    "Techniques to mitigate underfitting: \n",
    "1.Increase model complexity\n",
    "2.Increase the number of features, performing feature engineering\n",
    "3.Remove noise from the data.\n",
    "4.Increase the number of epochs or increase the duration of training to get better results.\n",
    "\n",
    "Overfitting: A statistical model is said to be overfitted when the model does not make accurate predictions on testing data. When a model gets trained with so much data, it starts learning from the noise and inaccurate data entries in our data set. And when testing with test data results in High variance. \n",
    "The causes of overfitting are the non-parametric and non-linear methods because these types of machine learning algorithms have more freedom in building the model based on the dataset and therefore they can really build unrealistic models.\n",
    "\n",
    "Techniques to mitigate underfitting: \n",
    "Increase training data.\n",
    "Reduce model complexity.\n",
    "Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
    "Ridge Regularization and Lasso Regularization\n",
    "Use dropout for neural networks to tackle overfitting.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76de41b",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d2d38",
   "metadata": {},
   "source": [
    "Techniques to reduce underfitting: \n",
    "1.Increase training data.\n",
    "2.Reduce model complexity.\n",
    "3.Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
    "4.Ridge Regularization and Lasso Regularization\n",
    "5.Use dropout for neural networks to tackle overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612719b",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b7043",
   "metadata": {},
   "source": [
    "A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data, i.e., it only performs well on training data but performs poorly on testing data.\n",
    "Scenarios of underfitting-\n",
    "1.High bias and low variance \n",
    "2.The size of the training dataset used is not enough.\n",
    "3.The model is too simple.\n",
    "4.Training data is not cleaned and also contains noise in it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e8b89",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa27ce",
   "metadata": {},
   "source": [
    "“Bias and variance are complements of each other” The increase of one will result in the decrease of the other and vice versa. Hence, finding the right balance of values is known as the Bias-Variance Tradeoff.\n",
    "The difference between the average value predicted by our Machine Learning model and the correct target value is known as Bias.\n",
    "The amount of variability in the target function in response to a change in the training data is known as Variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf213533",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd0cc1",
   "metadata": {},
   "source": [
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data.\n",
    "Your model is underfitting the training data when the model performs poorly on the training data.\n",
    "Your model is overfitting your training data when you see that the model performs well on the training data but does not perform well on the evaluation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dd1fa8",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab0ac5",
   "metadata": {},
   "source": [
    "The difference between the average value predicted by our Machine Learning model and the correct target value is known as Bias. The amount of variability in the target function in response to a change in the training data is known as Variance.\n",
    "Examples of high-bias machine learning algorithms include: Linear Regression, Linear Discriminant Analysis and Logistic Regression.\n",
    "Examples of high-variance machine learning algorithms include: Decision Trees, k-Nearest Neighbors and Support Vector Machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfbad3",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eefbbf",
   "metadata": {},
   "source": [
    "Regularization in machine learning is the process of regularizing the parameters that constrain, regularizes, or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, avoiding the risk of Overfitting.\n",
    "Different Regularization Techniques in deep learning\n",
    "L2 & L1 regularization\n",
    "Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2be0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
