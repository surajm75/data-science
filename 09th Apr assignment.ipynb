{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef9faee",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec75c24",
   "metadata": {},
   "source": [
    "Bayes' Theorem is a fundamental concept in probability theory and statistics. It describes how to update the probability of a hypothesis (an event or proposition) based on new evidence or information. The theorem is named after Thomas Bayes, an 18th-century mathematician and theologian, who contributed to its development.\n",
    "\n",
    "Bayes' Theorem is a powerful tool for updating probabilities based on new information. It has numerous applications in various fields, including machine learning, data science, medical diagnosis, natural language processing, and more. It provides a systematic way to combine prior beliefs with observed evidence, making it an essential concept in Bayesian inference and probabilistic reasoning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d02013",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5133c2",
   "metadata": {},
   "source": [
    "Mathematically, Bayes' Theorem can be expressed as follows:\n",
    "P(A∣B)= P(B∣A)⋅P(A)/P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A∣B) is the posterior probability of event A given event B has occurred.\n",
    "\n",
    "P(B∣A) is the likelihood of event B occurring given that event A has occurred.\n",
    "\n",
    "P(A) is the prior probability of event A.\n",
    "\n",
    "P(B) is the probability of event B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67529de",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806506b",
   "metadata": {},
   "source": [
    "Bayes' Theorem is used in practice to make informed decisions, update beliefs, and perform probabilistic reasoning in various fields. Here are some practical applications of Bayes' Theorem:\n",
    "\n",
    "Medical Diagnosis: Bayes' Theorem is used in medical diagnosis to calculate the probability of a disease given certain symptoms. Medical professionals combine prior probabilities of diseases with the likelihood of observing symptoms to make accurate diagnoses.\n",
    "\n",
    "Spam Filtering: In email spam filtering, Bayes' Theorem helps classify emails as spam or not spam. The theorem is used to update the probability of an email being spam based on observed keywords and features.\n",
    "\n",
    "Machine Learning: Bayes' Theorem is a cornerstone of Bayesian machine learning algorithms. It's used in Bayesian classifiers and probabilistic models to make predictions and decisions based on observed data.\n",
    "\n",
    "A/B Testing: Bayes' Theorem can be used to analyze the results of A/B tests by updating the prior belief about a hypothesis (e.g., a change in a website's design) based on the observed data.\n",
    "\n",
    "Predictive Modeling: Bayes' Theorem is used in predictive modeling to update prior beliefs about model parameters based on new data. This is common in Bayesian regression and Bayesian neural networks.\n",
    "\n",
    "Natural Language Processing: In language modeling, Bayes' Theorem helps calculate the probability of a word given the previous words, enabling applications like speech recognition and machine translation.\n",
    "\n",
    "Forensics: Bayes' Theorem is used in forensic science to calculate the likelihood of evidence given a hypothesis, helping to quantify the strength of the evidence in criminal investigations.\n",
    "\n",
    "Financial Modeling: Bayes' Theorem is used in financial modeling to update the probabilities of different market outcomes based on new economic data.\n",
    "\n",
    "Weather Forecasting: Bayesian methods are applied in weather forecasting to update the probability distribution of weather conditions as new data becomes available.\n",
    "\n",
    "Risk Assessment: In risk assessment, Bayes' Theorem can be used to calculate the probability of an event occurring based on new information, adjusting the initial risk estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd4be2",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c56be",
   "metadata": {},
   "source": [
    "The key relationship between Bayes' Theorem and conditional probability is that Bayes' Theorem provides a way to update the conditional probability P(A∣B) using additional information, specifically P(B∣A) and prior probabilities P(A) and P(B).\n",
    "\n",
    "Bayes' Theorem allows us to reverse the roles of the two events. If we know P(B∣A), we can use Bayes' Theorem to calculate P(A∣B). This is particularly useful when we have information about the likelihood of observing evidence (B) given a hypothesis (A), and we want to update our belief about the hypothesis based on that evidence.\n",
    "\n",
    "In summary, while conditional probability calculates the likelihood of one event given another event, Bayes' Theorem extends this concept by providing a formal way to update conditional probabilities using prior information and observed evidence.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbb689",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa64cca8",
   "metadata": {},
   "source": [
    "Choosing the appropriate type of Naive Bayes classifier for a given problem depends on the nature of the data and the assumptions that align with the problem's characteristics. There are three common types of Naive Bayes classifiers: Gaussian, Multinomial, and Bernoulli. Here's how to choose:\n",
    "\n",
    "Gaussian Naive Bayes:\n",
    "Use Gaussian Naive Bayes when your features follow a Gaussian (normal) distribution. This classifier is suitable for continuous numeric data. If your data's distribution is roughly bell-shaped and continuous, Gaussian Naive Bayes might be a good choice.\n",
    "\n",
    "Multinomial Naive Bayes:\n",
    "Choose Multinomial Naive Bayes when dealing with discrete data, particularly when the features represent counts or frequencies. It's often used in text classification, where features could be word frequencies. If your data is represented as counts or frequencies and has multiple categories, Multinomial Naive Bayes is suitable.\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "Opt for Bernoulli Naive Bayes when dealing with binary or Boolean features. This classifier works well when your features are binary, such as presence or absence of certain attributes. It's commonly used in sentiment analysis or spam detection tasks where the presence of specific words is important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117aaa2",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a78be9",
   "metadata": {},
   "source": [
    "For Class A:\n",
    "\n",
    "P(X1 = 3 | A) = 4 / 10\n",
    "P(X2 = 4 | A) = 3 / 13\n",
    "\n",
    "For Class B:\n",
    "\n",
    "P(X1 = 3 | B) = 1 / 5\n",
    "P(X2 = 4 | B) = 3 / 9\n",
    "\n",
    "P(A) = P(B) = 0.5\n",
    "\n",
    "For Class A:\n",
    "P(A∣X1=3,X2=4)=P(X1=3∣A)×P(X2=4∣A)×P(A) = 0.046\n",
    "\n",
    "For Class B:\n",
    "P(B∣X1=3,X2=4)=P(X1=3∣B)×P(X2=4∣B)×P(B) = 0.033\n",
    "\n",
    "Since \n",
    "\n",
    "P(A∣X1=3,X2=4)>P(B∣X1=3,X2=4), Naive Bayes would predict that the new instance belongs to Class A.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b381af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
